{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15615b6e",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/polyhedron-gdl/unibo-intensive-program-2023/blob/main/1-notebooks/chapter-2-4.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564a48c",
   "metadata": {},
   "source": [
    "# Convnet in Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e91ff6",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNNs) have been applied to a variety of finance-related tasks, such as stock price prediction, fraud detection, and risk assessment. Here's a simple example of how a CNN could be used for stock price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb074fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are in google colab probably you need to install yfinance\n",
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4dda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas   as pd\n",
    "import numpy    as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0917b6",
   "metadata": {},
   "source": [
    "## Download Stock Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e25e75",
   "metadata": {},
   "source": [
    "Here's an example Python code that uses the yfinance library to download stock prices for a specified set of tickers, and saves the results to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e85ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>72.482498</td>\n",
       "      <td>73.419998</td>\n",
       "      <td>72.379997</td>\n",
       "      <td>73.412498</td>\n",
       "      <td>71.810936</td>\n",
       "      <td>100805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>74.059998</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>73.797501</td>\n",
       "      <td>75.087502</td>\n",
       "      <td>73.449387</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>74.287498</td>\n",
       "      <td>75.144997</td>\n",
       "      <td>74.125000</td>\n",
       "      <td>74.357498</td>\n",
       "      <td>72.735313</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>73.447502</td>\n",
       "      <td>74.989998</td>\n",
       "      <td>73.187500</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>73.314888</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>74.959999</td>\n",
       "      <td>75.224998</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>72.970093</td>\n",
       "      <td>108872000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2019-12-31  72.482498  73.419998  72.379997  73.412498  71.810936  100805600\n",
       "2020-01-02  74.059998  75.150002  73.797501  75.087502  73.449387  135480400\n",
       "2020-01-03  74.287498  75.144997  74.125000  74.357498  72.735313  146322800\n",
       "2020-01-06  73.447502  74.989998  73.187500  74.949997  73.314888  118387200\n",
       "2020-01-07  74.959999  75.224998  74.370003  74.597504  72.970093  108872000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list of tickers to download\n",
    "#tickers = [\"AAPL\", \"MSFT\", \"AMZN\"]\n",
    "tickers = [\"AAPL\"]\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = \"2020-01-01\"\n",
    "end_date   = \"2021-12-31\"\n",
    "\n",
    "# Download the stock data for the specified tickers and dates\n",
    "data = yf.download(tickers, start=start_date, end=end_date)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a CSV file\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # if we run in google environment first we save in virtual machine...\n",
    "    data.to_csv ('stock_prices.csv', index = 'Date', header=True)\n",
    "    # ...then we download to local machine\n",
    "    from google.colab import files\n",
    "    files.download(\"stock_prices.csv\")    \n",
    "else:\n",
    "    # if we are working in local we save directly with the usual method\n",
    "    data.to_csv ('./data/stock_prices.csv', index = 'Date', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996f739",
   "metadata": {},
   "source": [
    "In this example, we import the `yfinance` library to access the Yahoo Finance API. We then define a list of tickers we want to download, as well as start and end dates. We pass these parameters to the `yf.download` function, which returns a pandas DataFrame containing the stock data for the specified tickers and dates.\n",
    "\n",
    "Finally, we use the `to_csv` method of the DataFrame to save the data to a CSV file named `stock_prices.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378eed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e3e51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>72.482498</td>\n",
       "      <td>73.419998</td>\n",
       "      <td>72.379997</td>\n",
       "      <td>73.412498</td>\n",
       "      <td>71.810936</td>\n",
       "      <td>100805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>73.797501</td>\n",
       "      <td>75.087502</td>\n",
       "      <td>73.449387</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>74.287498</td>\n",
       "      <td>75.144997</td>\n",
       "      <td>74.125000</td>\n",
       "      <td>74.357498</td>\n",
       "      <td>72.735313</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.447502</td>\n",
       "      <td>74.989998</td>\n",
       "      <td>73.187500</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>73.314888</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>74.959999</td>\n",
       "      <td>75.224998</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>72.970093</td>\n",
       "      <td>108872000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2019-12-31  72.482498  73.419998  72.379997  73.412498  71.810936   \n",
       "1  2020-01-02  74.059998  75.150002  73.797501  75.087502  73.449387   \n",
       "2  2020-01-03  74.287498  75.144997  74.125000  74.357498  72.735313   \n",
       "3  2020-01-06  73.447502  74.989998  73.187500  74.949997  73.314888   \n",
       "4  2020-01-07  74.959999  75.224998  74.370003  74.597504  72.970093   \n",
       "\n",
       "      Volume  \n",
       "0  100805600  \n",
       "1  135480400  \n",
       "2  146322800  \n",
       "3  118387200  \n",
       "4  108872000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the historical stock prices\n",
    "df = pd.read_csv(path + 'stock_prices.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114c08c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the date column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the 'Close' column\n",
    "df['Close'].plot()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde0e2f",
   "metadata": {},
   "source": [
    "## Predicting Stock Closing Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8ef90",
   "metadata": {},
   "source": [
    "Suppose we want to predict the daily closing price of a particular stock based on its historical prices. We can train a CNN on a sequence of historical prices and use it to predict the next day's closing price. Here's some sample code that shows how this might be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7ac0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59c84c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    }
   ],
   "source": [
    "# Convert the closing prices to a numpy array\n",
    "closing_prices = df['Close'].values\n",
    "print(len(closing_prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808bc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the length of the input sequence and the number of output classes\n",
    "seq_length  = 30\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef1c09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(seq_length, len(closing_prices) - 1):\n",
    "    X_train.append(closing_prices[i - seq_length:i])\n",
    "    y_train.append(closing_prices[i + 1])\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3f86eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(474, 30)\n",
      "(474,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bb1b2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.41249847, 75.08750153, 74.35749817, 74.94999695, 74.59750366,\n",
       "       75.79750061, 77.40750122, 77.58249664, 79.23999786, 78.16999817,\n",
       "       77.83499908, 78.80999756, 79.68250275, 79.14250183, 79.42500305,\n",
       "       79.80750275, 79.57749939, 77.23750305, 79.42250061, 81.08499908,\n",
       "       80.96749878, 77.37750244, 77.16500092, 79.71250153, 80.36250305,\n",
       "       81.30249786, 80.00749969, 80.38749695, 79.90249634, 81.80000305])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de33a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 26, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 8, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 6, 128)            24704     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 4, 128)            49280     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                6450      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,093\n",
      "Trainable params: 93,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(seq_length, num_classes)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18fd0b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 6700.2715\n",
      "Epoch 2/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 479.9174\n",
      "Epoch 3/10000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 205.4891\n",
      "Epoch 4/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 92.3229\n",
      "Epoch 5/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 77.9640\n",
      "Epoch 6/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 75.6433\n",
      "Epoch 7/10000\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 74.5412\n",
      "Epoch 8/10000\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 74.7080\n",
      "Epoch 9/10000\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 74.5422\n",
      "Epoch 10/10000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 74.0575\n",
      "Epoch 11/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 74.5985\n",
      "Epoch 12/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 78.3341\n",
      "Epoch 13/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 76.7739\n",
      "Epoch 14/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 76.5782\n",
      "Epoch 15/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 72.8388\n",
      "Epoch 16/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 72.4412\n",
      "Epoch 17/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 71.9616\n",
      "Epoch 18/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 72.9706\n",
      "Epoch 19/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 74.1014\n",
      "Epoch 20/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 83.7596\n",
      "Epoch 21/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 75.8868\n",
      "Epoch 22/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 70.9018\n",
      "Epoch 23/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 72.1517\n",
      "Epoch 24/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 71.7205\n",
      "Epoch 25/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 72.4543\n",
      "Epoch 26/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 76.6365\n",
      "Epoch 27/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 74.9807\n",
      "Epoch 28/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 71.1066\n",
      "Epoch 29/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 71.1772\n",
      "Epoch 30/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 69.6187\n",
      "Epoch 31/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 79.6393\n",
      "Epoch 32/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 77.8151\n",
      "Epoch 33/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 70.2945\n",
      "Epoch 34/10000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 68.7729\n",
      "Epoch 35/10000\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 69.2011\n",
      "Epoch 36/10000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 70.3320\n",
      "Epoch 37/10000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 65.8427\n",
      "Epoch 38/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 73.3002\n",
      "Epoch 39/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 69.5020\n",
      "Epoch 40/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 68.1115\n",
      "Epoch 41/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 63.9470\n",
      "Epoch 42/10000\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 73.5464\n",
      "Epoch 43/10000\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 72.9835\n",
      "Epoch 44/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 71.0453\n",
      "Epoch 45/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 64.6959\n",
      "Epoch 46/10000\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 62.6926\n",
      "Epoch 47/10000\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 62.7254\n",
      "Epoch 48/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 61.2969\n",
      "Epoch 49/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 62.1224\n",
      "Epoch 50/10000\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 68.3483\n",
      "Epoch 51/10000\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 71.3405"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6940\\913911850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1105\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m       \u001b[0mio_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     35\u001b[0m       \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m       \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    545\u001b[0m                 )\n\u001b[0;32m    546\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3737094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the next day's closing price\n",
    "last_seq = closing_prices[-seq_length:]\n",
    "prediction = model.predict(np.array([last_seq]))\n",
    "print('The predicted closing price is:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9034d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(last_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(last_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(tickers, start=\"2022-01-03\", end=\"2022-01-31\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54843ac9",
   "metadata": {},
   "source": [
    "In this example, we first load the historical stock prices from a CSV file. We then define the length of the input sequence (30 days, in this case) and the number of output classes (1, since we are predicting a single value). We construct the training data by using a sliding window approach to create input/output pairs from the historical prices.\n",
    "\n",
    "We then construct a CNN model with several convolutional layers and dense layers, and compile it using the mean squared error loss function. We train the model on the training data, and then use it to predict the next day's closing price based on the most recent sequence of historical prices.\n",
    "\n",
    "Note that this is just a simple example, and there are many ways to improve and customize this model for a particular finance-related task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90587ce",
   "metadata": {},
   "source": [
    "## Exercise - Predicting Change in Stock Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7c198",
   "metadata": {},
   "source": [
    "A possible application of CNNs in financial risk management is to predict changes in financial market volatility. Here's an example of how you could use a CNN to predict volatility changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a13bf222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d49333d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical stock price data for a given stock\n",
    "data = pd.read_csv('stock_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20c5a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily log returns and the corresponding volatility\n",
    "data['Log Returns'] = data['Adj Close'].pct_change(-1)   #np.log(data['Adj Close']) - np.log(data['Adj Close'].shift(1))\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10cdf824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Volatility']  = data['Log Returns'].rolling(window=5).std() * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381e244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the volatility data\n",
    "scaler = MinMaxScaler()\n",
    "data['Normalized Volatility'] = scaler.fit_transform(data['Volatility'].values.reshape(-1, 1))\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a53d6b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Log Returns</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Normalized Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>74.959999</td>\n",
       "      <td>75.224998</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>72.970085</td>\n",
       "      <td>108872000</td>\n",
       "      <td>-0.015832</td>\n",
       "      <td>0.214596</td>\n",
       "      <td>0.104649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>76.110001</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>75.797501</td>\n",
       "      <td>74.143898</td>\n",
       "      <td>132079200</td>\n",
       "      <td>-0.020799</td>\n",
       "      <td>0.207665</td>\n",
       "      <td>0.100589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>76.809998</td>\n",
       "      <td>77.607498</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>77.407501</td>\n",
       "      <td>75.718788</td>\n",
       "      <td>170108400</td>\n",
       "      <td>-0.002256</td>\n",
       "      <td>0.162517</td>\n",
       "      <td>0.074142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>77.650002</td>\n",
       "      <td>78.167503</td>\n",
       "      <td>77.062500</td>\n",
       "      <td>77.582497</td>\n",
       "      <td>75.889961</td>\n",
       "      <td>140644800</td>\n",
       "      <td>-0.020917</td>\n",
       "      <td>0.184695</td>\n",
       "      <td>0.087133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>77.910004</td>\n",
       "      <td>79.267502</td>\n",
       "      <td>77.787498</td>\n",
       "      <td>79.239998</td>\n",
       "      <td>77.511284</td>\n",
       "      <td>121532000</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.236511</td>\n",
       "      <td>0.117486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "4  2020-01-07  74.959999  75.224998  74.370003  74.597504  72.970085   \n",
       "5  2020-01-08  74.290001  76.110001  74.290001  75.797501  74.143898   \n",
       "6  2020-01-09  76.809998  77.607498  76.550003  77.407501  75.718788   \n",
       "7  2020-01-10  77.650002  78.167503  77.062500  77.582497  75.889961   \n",
       "8  2020-01-13  77.910004  79.267502  77.787498  79.239998  77.511284   \n",
       "\n",
       "      Volume  Log Returns  Volatility  Normalized Volatility  \n",
       "4  108872000    -0.015832    0.214596               0.104649  \n",
       "5  132079200    -0.020799    0.207665               0.100589  \n",
       "6  170108400    -0.002256    0.162517               0.074142  \n",
       "7  140644800    -0.020917    0.184695               0.087133  \n",
       "8  121532000     0.013688    0.236511               0.117486  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83ca305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the input and output sequences\n",
    "N = 30\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "037a55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and output sequences by taking a sliding window of past volatility values\n",
    "X, Y = [], []\n",
    "for i in range(N, len(data)):\n",
    "    x_i = data['Normalized Volatility'].values[(i-N):i]\n",
    "    y_i = data['Normalized Volatility'].values[i:(i+K)]\n",
    "    X.append(x_i)\n",
    "    Y.append(y_i)\n",
    "X, Y = np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8014327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(data))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "Y_train, Y_test = Y[:split], Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53b27e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85a8015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 1s 4ms/step - loss: 0.0186\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0122\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0115\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0094\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0086\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0094\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0023\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 9.1614e-04\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c486a39948>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a239c0",
   "metadata": {},
   "source": [
    "### Does it Work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c995970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Test loss: 0.0033224106300622225\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the CNN on the testing set\n",
    "test_loss = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5bc3157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted volatility change: 0.31403893\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new, unseen data\n",
    "X_new = np.array([data['Normalized Volatility'].values[-N:]])\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred = scaler.inverse_transform(y_pred)[0][0]\n",
    "print(\"Predicted volatility change:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501026a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
